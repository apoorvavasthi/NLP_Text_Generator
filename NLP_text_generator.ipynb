{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZsZ4csLaEpIG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "KNd6JKpdEycX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8n6JqZdE3ci",
        "outputId": "27cea711-20c2-496a-9352-0a7b5ae94329"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file=\"/content/drive/My Drive/Datasets for practice/shakespeare.txt\""
      ],
      "metadata": {
        "id": "amE_L1s0F9qe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=open(path_to_file,'r').read()"
      ],
      "metadata": {
        "id": "26rmAxP7HO5o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(text[:500])"
      ],
      "metadata": {
        "id": "-fCrzraLHYu8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=(sorted(set(text)))"
      ],
      "metadata": {
        "id": "uRPTTvAGHakM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QFDXnLVIB_w",
        "outputId": "1f3ce605-f140-43bf-f39f-42ce201d3b90"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for pairs in enumerate(vocab):\n",
        "#   print(pairs)"
      ],
      "metadata": {
        "id": "izOzAyxsIOH-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num= {char:num for num,char in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "as0g6RNtIw_7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbiWNzbHJPRl",
        "outputId": "78a965bc-b504-4568-b045-351696425b85"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82,\n",
              " '}': 83}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_to_char=np.array(vocab) "
      ],
      "metadata": {
        "id": "-mSAYgwOJQwp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_to_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdLDkRohJevZ",
        "outputId": "b9b182d7-7d8b-4a8d-ffb7-6cbba0164c58"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
              "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
              "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
              "       'w', 'x', 'y', 'z', '|', '}'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text=np.array([char_to_num[c] for c in text])"
      ],
      "metadata": {
        "id": "AoOijlBkJkV2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68j4b-k4KEPs",
        "outputId": "58be7172-d22f-40e4-9ffb-0bac45d71fb1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5445609"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample=text[:500]\n",
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sG4HNZ1LCpK",
        "outputId": "f5e47d4d-1d24-4762-d529-294ddde69cc2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DH6wfsQLTMp",
        "outputId": "2bad99d4-886f-41b0-fa32-959f0db8c1dd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
              "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
              "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
              "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
              "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
              "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
              "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
              "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
              "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
              "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
              "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
              "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
              "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
              "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
              "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
              "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
              "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
              "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
              "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
              "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
              "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
              "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
              "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
              "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
              "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
              "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
              "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
              "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
              "        1, 70, 78, 69,  1, 57, 76])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line='From fairest creatures we desire increase'\n",
        "len(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSFQFOhgLYHK",
        "outputId": "f6b15d33-5a68-411f-cba2-d6f7a8b40dd9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "para='''From fairest creatures we desire increase,That thereby beauty's rose might never die But as the riper should by time decease'''\n",
        "len(para)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvsAEELXL8Wp",
        "outputId": "c34183dc-2d76-49cc-c842-be8a29a0737a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len=120 #taking avg of the unique para "
      ],
      "metadata": {
        "id": "JKbSY6g-MGMl"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_seq=len(text)//(seq_len+1)  # '//' is used to round off the values"
      ],
      "metadata": {
        "id": "XrYHrktEMeor"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QFBuO-bMp7v",
        "outputId": "d99ace1d-29df-4896-d24e-b4d9d425017b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_dataset=tf.data.Dataset.from_tensor_slices(encoded_text)"
      ],
      "metadata": {
        "id": "olXgMdzUMsGG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(char_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAihZoZ6M8yD",
        "outputId": "74539fbb-cfd4-4ab8-fc86-079d28250809"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = char_dataset.batch(seq_len+1,drop_remainder=True)"
      ],
      "metadata": {
        "id": "o_jGOqjSNU6f"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_seq_targets(seq):\n",
        "  input_txt=seq[:-1] # Hello my nam\n",
        "  target_txt=seq[1:] # ello my name\n",
        "  return input_txt,target_txt"
      ],
      "metadata": {
        "id": "nL9rKuuOOG7m"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=sequence.map(create_seq_targets)"
      ],
      "metadata": {
        "id": "U6jE_JLHOup0"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_txt,target_txt in dataset.take(1):\n",
        "  print(input_txt.numpy())\n",
        "  print(\"\".join(num_to_char[input_txt.numpy()]))\n",
        "  print('\\n')\n",
        "  print(target_txt.numpy())\n",
        "  print(\"\".join(num_to_char[target_txt.numpy()]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19ZQH_IbPCtO",
        "outputId": "063110a1-0c08-419e-89d6-74fe85998288"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128"
      ],
      "metadata": {
        "id": "XGuMhiNTP9Sq"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_size=1000\n",
        "dataset=dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
      ],
      "metadata": {
        "id": "O3UiNV1xQGhS"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FARuXyDQQYk1",
        "outputId": "5cae0163-4f1b-47c5-9a08-3ab9e9ebce28"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(vocab)"
      ],
      "metadata": {
        "id": "p67POnNcQl1D"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msmn2630RH7k",
        "outputId": "f2c6300a-dcfb-40a2-eef2-2772713b7888"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim=64"
      ],
      "metadata": {
        "id": "wE9g8gTCRJh_"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_neurons=1026"
      ],
      "metadata": {
        "id": "84PFx8D5RLmy"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "WBmO3fwQROsd"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(sparse_categorical_crossentropy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lBE_FwbRYdg",
        "outputId": "67d9d239-2119-4285-e6bd-c77136606069"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function sparse_categorical_crossentropy in module keras.losses:\n",
            "\n",
            "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1, ignore_class=None)\n",
            "    Computes the sparse categorical crossentropy loss.\n",
            "    \n",
            "    Standalone usage:\n",
            "    \n",
            "    >>> y_true = [1, 2]\n",
            "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
            "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
            "    >>> assert loss.shape == (2,)\n",
            "    >>> loss.numpy()\n",
            "    array([0.0513, 2.303], dtype=float32)\n",
            "    \n",
            "    >>> y_true = [[[ 0,  2],\n",
            "    ...            [-1, -1]],\n",
            "    ...           [[ 0,  2],\n",
            "    ...            [-1, -1]]]\n",
            "    >>> y_pred = [[[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n",
            "    ...             [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]],\n",
            "    ...           [[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n",
            "    ...            [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]]\n",
            "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
            "    ...   y_true, y_pred, ignore_class=-1)\n",
            "    >>> loss.numpy()\n",
            "    array([[[2.3841855e-07, 2.3841855e-07],\n",
            "            [0.0000000e+00, 0.0000000e+00]],\n",
            "           [[2.3841855e-07, 6.9314730e-01],\n",
            "            [0.0000000e+00, 0.0000000e+00]]], dtype=float32)\n",
            "    \n",
            "    Args:\n",
            "      y_true: Ground truth values.\n",
            "      y_pred: The predicted values.\n",
            "      from_logits: Whether `y_pred` is expected to be a logits tensor. By\n",
            "        default, we assume that `y_pred` encodes a probability distribution.\n",
            "      axis: Defaults to -1. The dimension along which the entropy is\n",
            "        computed.\n",
            "      ignore_class: Optional integer. The ID of a class to be ignored during\n",
            "        loss computation. This is useful, for example, in segmentation\n",
            "        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n",
            "        maps. By default (`ignore_class=None`), all classes are considered.\n",
            "    \n",
            "    Returns:\n",
            "      Sparse categorical crossentropy loss value.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True)"
      ],
      "metadata": {
        "id": "8OYa5Z8rRcGy"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,GRU,Dense"
      ],
      "metadata": {
        "id": "UzKRxWsMSE3l"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vocab_size,embed_dim,rnn_neurons,batch_size):\n",
        "  model=Sequential()\n",
        "  model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
        "  model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "  model.add(Dense(vocab_size))\n",
        "\n",
        "  model.compile('adam',loss=sparse_cat_loss)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "cS1N3J8hRyJS"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =create_model(vocab_size=vocab_size,\n",
        "                    embed_dim=embed_dim,\n",
        "                    rnn_neurons=rnn_neurons,\n",
        "                    batch_size=batch_size)"
      ],
      "metadata": {
        "id": "pI3YcIBXTL9b"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovY-5c7IT0Uo",
        "outputId": "f1a30c65-2ad2-4c25-c910-f86274ff9ebd"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (128, None, 64)           5376      \n",
            "                                                                 \n",
            " gru (GRU)                   (128, None, 1026)         3361176   \n",
            "                                                                 \n",
            " dense (Dense)               (128, None, 84)           86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch,target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions=model(input_example_batch)"
      ],
      "metadata": {
        "id": "im1sborKU2xU"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_indices=tf.random.categorical(example_batch_predictions[0],num_samples=1)"
      ],
      "metadata": {
        "id": "GIT1LD33WDAm"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices=tf.squeeze(sample_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "_YE0m3BBWIAw"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#num_to_char[sampled_indices]"
      ],
      "metadata": {
        "id": "mvG3sO6PWlI7"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=30"
      ],
      "metadata": {
        "id": "_mrfPZwuW9pa"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.fit(dataset,epochs=epochs)"
      ],
      "metadata": {
        "id": "wc5t3ImUXIoc"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for loading the model\n",
        "from tensorflow.keras.models import load_model\n"
      ],
      "metadata": {
        "id": "Vn-GsMiTXR6N"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size,embed_dim,rnn_neuron,batch_size=1)\n",
        "\n",
        "model.load_weights(\"/content/drive/My Drive/Datasets for practice/shakespeare_gen.h5\")\n",
        "\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "metadata": {
        "id": "jltYBJ98Yg-m"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6gAYgIeZAFT",
        "outputId": "e809c161-dd9f-416b-a095-584959a387fe"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (1, None, 64)             5376      \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (1, None, 1026)           3361176   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (1, None, 84)             86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model,start_seed,gen_size=500,temp=1.0):\n",
        "  num_generator=gen_size\n",
        "  input_eval=[char_to_num[s] for s in start_seed]\n",
        "\n",
        "  input_eval=tf.expand_dims(input_eval,0)\n",
        "\n",
        "  text_generated =[]\n",
        "\n",
        "  temperature=temp\n",
        "\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range (num_generator):\n",
        "    predictions=model(input_eval)\n",
        "    predictions=tf.squeeze(predictions,0)\n",
        "    predictions=predictions/temperature\n",
        "\n",
        "    predicted_id=tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    input_eval=tf.expand_dims([predicted_id],0)\n",
        "\n",
        "    text_generated.append(num_to_char[predicted_id])\n",
        "\n",
        "  return (start_seed+\"\".join(text_generated))"
      ],
      "metadata": {
        "id": "751Pr3w5ZGf_"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model,\"JULIET\",gen_size=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoRG4ybybPni",
        "outputId": "15b25c71-27e2-4aaa-c91f-f544e1c7b395"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JULIETHETHERS\n",
            "PERSONAL USE ONLY, AND (2) ARE NOT DISTRIBUTED OR USED\n",
            "COMMERCIALLY.  PROHIBITED COMMERCIAL DISTRIBUTION INCLUDES BY ANY\n",
            "SERVICE THAT CHARGES FOR DOWNLOAD TIME OR FOR MEMBERSHIP.>>\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1595\n",
            "\n",
            "THE LING'S hand to horse!\n",
            "    There, to a worthy and most kind his name\n",
            "    With full fortunes considered. Too late against\n",
            "    The Duke.\n",
            "  QUEEN. Noble hearted garments, my dear Gratiano,\n",
            "    Commit it up, I pray; and what to justice\n",
            "    Must I bite my sword, he did lose this life.\n",
            "  BEROWNE. This sir Reads with my company; he start; because I\n",
            "    am familiar right and sauciently. He said\n",
            "    From shrilling passion should put me his brain.\n",
            "\n",
            "          Exeunt CLOTEN and CLIFFORD\n",
            "                AJAX, MARd, and histor for pale\n",
            "    That is your servant, madcheth purpose breaking?\n",
            "    This way! my lord, your Grace wilt give it her.\n",
            "    A stranger here is a rebels' by't\n",
            "    to tellout shameless year since? -\n",
            "  PROTEUS. You make me to me show.\n",
            "    The King is sp chaced forth;\n",
            "    Till I dissolve\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O7FeF8vIbYKd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}